unet_model_reconstruct.pb;1,256,256,3
ml_video_edit_generate_filter.pb
densenet.pb;1,224,224,3
inception_resnet_v2.pb;1,299,299,3
inception_v3.pb;1,299,299,3
inception_v4.pb;1,299,299,3
mnasnet_1.0_224.pb
mnasnet_1.3_224.pb
mobilenet_v1_0.25_128_frozen.pb;1,128,128,3
mobilenet_v2_1.0_224_frozen.pb;1,224,224,3
nasnet_large.pb;1,331,331,3
nasnet_mobile.pb;1,224,224,3
squeezenet.pb;1,224,224,3
ml_ei_headpose.pb;1,64,64,3
ml_ei_landmark.pb;1,160,160,3
ml_face_openclose.pb;1,32,32,3
ml_object_detect.pb;1,288,288,3
ml_ocr_jk.pb
ml_video_edit_enhance.pb
ml_vision_guide_detection1.pb
ml_vision_guide_detection3.pb
scan_hms_angle.pb
scan_hms_detect.pb
hiai_AADB_HADB_MBV2_model.pb;1,224,224,3
hiai_cn_recognize_modify_padv2.pb;1,32,512,1
hiai_cpu_face_emotion.pb
hiai_cpu_face_gazing.pb
hiai_cpu_face_headpose.pb
hiai_ctpn_feature_map.pb
hiai_cv_focusShootOCRModel_02.pb
hiai_cv_focusShootOCRModel_08.pb
hiai_cv_poseEstimation.pb
hiai_detectmodel_06_23_960_480_1180700.pb
hiai_dress_detect.pb;1,960,960,3
hiai_face_model_npu.pb
hiai_frozen_inference_graph.pb;1,300,300,3
hiai_ghostnet.pb
hiai_iMaxDN_RGB.pb
hiai_iMaxSR_RGB.pb
hiai_label_and_video.pb;1,224,224,3
hiai_latin_ocr.pb
hiai_latin_ocr_1.pb
hiai_lm_inference_graph.pb
hiai_model_0909_kd_rot_ps_softmax.pb;1,224,224,3
hiai_PoseEstimation_Pcm.pb
model_normalize_object_scene_ps_20200519.pb;1,224,224,3
mtk_AADB_HADB_MBV2_model.pb;1,224,224,3
mtk_AADB_HADB_MBV3_model.pb;1,224,224,3
mtk_age_gender.pb
mtk_model_ckpt.pb
mtk_model_face_dress.pb;1,128,128,3
mtk_model_normalize_object_scene_ps_20200519.pb;1,224,224,3
ml_ocr_latin.pb
ml_noya_tts_melgan.pb;16,16,80
# Q_hand_0812.pb is not suitable for float16. Out of float16 range.
Q_hand_0812.pb
Q_inception-249970-672-11-16.pb
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid.pb
Q_crnn_screen_slim400w_more_20w.pb
matmul.pb
hiai_ssd_mobilenetv2_object.pb
hiai_humanDetection.pb
hiai_model_normalize_object_scene_ps_20200519.pb;1,224,224,3
mtk_face_features_v1.pb 
Q_crnn_ori_75w_slim_norm.pb
Q_crnn_ori_v2_405001_notrans_nopre.pb
